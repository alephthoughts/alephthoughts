{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f346e389",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Optimizing Your Data Analysis with Malloy\"\n",
    "description: \"An experimental language for data.\"\n",
    "author: \"Abhishek\"\n",
    "date: \"05/17/2023\"\n",
    "image: malloy-logo.png\n",
    "feed: true\n",
    "title-block-banner: \"../banner.png\"\n",
    "title-block-banner-color: \"#FFFFFF\"\n",
    "categories:\n",
    "  - tools\n",
    "  - data engineering\n",
    "  - malloy \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229b2a9",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "If you're someone who doesn't often write SQL, parts of this discussion may seem complex. However, if you're involved in data management, building interfaces, or working with databases, this blog post will prove insightful.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51bfdd3",
   "metadata": {},
   "source": [
    "# The Shift in Data Management\n",
    "\n",
    "Data is a crucial part of all organizations, and it's only when data is understood and utilised correctly, the businesses can truly thrive. Running a successful business today depends on the data and insights derived from it that make you smarter.\n",
    "A common misconception that surrounds data is that _data is rectangular_. That is, in fact, not true. Humans tend to visualize data as rectangles than leads to this misconception. Most operations that we perform on data such as filtering, aggregating, projecting, and windowing are all based on rectangular models. Even the join operation takes in two rectangles and gives a rectangle as the joined output.\n",
    "\n",
    "In a common ecommerce analysis you can expect two tables:\n",
    "\n",
    "__Orders__\n",
    "\n",
    "| order_id | order_date  | shipping_cost | user_id |\n",
    "| -------- | ----------- | ------------- | ------- |\n",
    "| 1        | 2022-01-01  | 2             | 1       |\n",
    "| 2        | 2022-01-01  | 3             | 2       |\n",
    "| 3        | 2022-01-02  | 1             | 1       |\n",
    "| 4        | 2022-01-02  | 23            | 3       |\n",
    "\n",
    "__Order Items__\n",
    "\n",
    "| item_id | order_id | item      | price |\n",
    "| ------- | -------- | --------- | ----- |\n",
    "| 1       | 1        | Chocolate | 2     |\n",
    "| 2       | 1        | Twizzler  | 1     |\n",
    "| 3       | 2        | Chocolate | 2     |\n",
    "| 4       | 2        | M and M   | 1     |\n",
    "| 5       | 3        | Twizzler  | 1     |\n",
    "| 6       | 4        | Fudge     | 3     |\n",
    "| 7       | 4        | Skittles  | 1     |\n",
    "\n",
    "Using the above tables let's calculate:\n",
    "\n",
    "- total_shipping\n",
    "- total_revenue\n",
    "\n",
    "__total_shipping__\n",
    "\n",
    "```\n",
    "SELECT\n",
    " sum(shipping_cost) AS total_shipping\n",
    "FROM orders\n",
    "```\n",
    "\n",
    "|total_shipping|\n",
    "|---|\n",
    "|8|\n",
    "\n",
    "__total_revenue__\n",
    "\n",
    "```\n",
    "SELECT\n",
    " sum(price) AS total_revenue\n",
    "FROM items\n",
    "```\n",
    "\n",
    "|total_revenue|\n",
    "|---|\n",
    "|11|\n",
    "\n",
    "Looking at the same calculation across the date dimension, we get:\n",
    "\n",
    "__total_shipping by date__\n",
    "\n",
    "```\n",
    "SELECT\n",
    " order_date,\n",
    " sum(shipping_cost) AS total_shipping\n",
    "FROM ‘orders.csv’\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "```\n",
    "| order_date  | total_shipping |\n",
    "| ----------- | -------------- |\n",
    "| 2022-01-01  | 5              |\n",
    "| 2022-01-02  | 3              |\n",
    "\n",
    "__total_revenue by date__\n",
    "\n",
    "```\n",
    "SELECT\n",
    " order_date,\n",
    " sum(price) AS total_revenue\n",
    "FROM ‘orders.csv’ AS orders\n",
    "JOIN ‘items.cvs’ AS items on\n",
    " orders.order_id = items.order_id\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "```\n",
    "\n",
    "| order_date  | total_revenue |\n",
    "| ----------- | ------------- |\n",
    "| 2022-01-01  | 6             |\n",
    "| 2022-01-02  | 5             |\n",
    "\n",
    "\n",
    "__How does revenue relate to shipping?__\n",
    "\n",
    "This is what we expect:\n",
    "\n",
    "| order_date  | total_revenue | total_shipping |\n",
    "| ----------- | ------------- | -------------- |\n",
    "| 2022-01-01  | 6             | 5              |\n",
    "| 2022-01-02  | 5             | 3              |\n",
    "\n",
    "This is what we get by joining:\n",
    "\n",
    "```\n",
    "SELECT\n",
    " orders.order_date,\n",
    " sum(items.price) AS total_revenue,\n",
    " sum(orders.shipping_cost) AS total_shipping\n",
    "FROM ‘orders.csv’ AS orders\n",
    "JOIN ‘items.cvs’ AS items ON orders.order_id = items.order_id\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "```\n",
    "\n",
    "| order_date  | total_revenue | total_shipping |\n",
    "| ----------- | ------------- | -------------- |\n",
    "| 2022-01-01  | 6             | <span style=\"color: amber;\">10</span> |\n",
    "| 2022-01-02  | 5             | <span style=\"color: amber;\">5</span>  |   \n",
    "\n",
    "The incorrect results happen because the order rows in the join are duplicated resulting in an overstated computation.\n",
    "\n",
    "```\n",
    "SELECT *\n",
    "FROM ‘orders.csv’ orders\n",
    "LEFT JOIN ‘items.csv’ AS items ON orders.order_id = items.order_id\n",
    "```\n",
    "\n",
    "| order_id | order_date  | shipping_cost | user_id | item_id | order_id | item      | price |\n",
    "| -------- | ----------- | ------------- | ------- | ------- | -------- | --------- | ----- |\n",
    "| 1        | 2022-01-01  | 2             | 1       | 2       | 1        | Twizzler  | 1     |\n",
    "| 2        | 2022-01-01  | 3             | 2       | 4       | 2        | M and M   | 1     |\n",
    "| 3        | 2022-01-02  | 1             | 1       | 5       | 3        | Twizzler  | 1     |\n",
    "| 4        | 2022-01-02  | 2             | 3       | 7       | 4        | Skittles  | 1     |\n",
    "| 1        | 2022-01-02  | 2             | 1       | 1       | 1        | Chocolate | 2     |\n",
    "| 2        | 2022-01-02  | 3             | 2       | 3       | 2        | Chocolate | 2     |\n",
    "| 4        | 2022-01-02  | 2             | 3       | 6       | 4        | Fudge     | 3     |\n",
    "\n",
    "# The Limitations of Traditional Data Warehousing and SQL\n",
    "\n",
    "## SQL Templates\n",
    "\n",
    "When using SQL, you will find yourself copying and pasting a lot, building queries with many templates. The issue lies in the fact that we operate in the rectangular context while the graph is network-based.\n",
    "\n",
    "From the `date` dimension the `total_shipping` and `total_revenue` look like this:\n",
    "\n",
    "![](measure_by_date.png \"Metrics over date dimension\")\n",
    "\n",
    "\n",
    "Now, suppose there is another dimension __user__ that looks like:\n",
    "\n",
    "| user_id | total_revenue | total_shipping |\n",
    "| ------- | ------------- | -------------- |\n",
    "| 1       | 4             | 3              |\n",
    "| 2       | 3             | 3              |\n",
    "| 3       | 4             | 2              |\n",
    "\n",
    "From the `user` dimension the `total_shipping` and `total_revenue` looks like this:\n",
    "\n",
    "![](measure_by_user.png \"Metrics over user dimension\")\n",
    "\n",
    "Hence we end up using a lot of query templates which may lead to copy-paste mistakes.\n",
    "\n",
    "## Data Warehouse Schema Design\n",
    "\n",
    "In trditional data warehousing, we often refer to the [Star Schema](https://en.wikipedia.org/wiki/Star_schema). This involves creating too many fact tables during ETL processes, with the unit of reusability being a table with some dimensionality. But the truth is, reusability should be about the data itself, not its definition.\n",
    "\n",
    "![](star_schema.png \"Example of star schema\")\n",
    "\n",
    "The star schema was designed during a time when the databases were slow and the data was relatively big. Another issue with this approach is the lack of real-time data processing. If you produce an intermittent artifact, it won't be real time, as these artifacts are produced and then joined later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4abf5",
   "metadata": {},
   "source": [
    "# Introducing Malloy - An experimental language for data\n",
    "\n",
    "[Malloy](https://www.malloydata.dev/), a revolutionary language for data, promises to transform the way we handle and view data. It ensures that join relations don't affect aggregate calculations, fundamentally changing the way we approach data.\n",
    "\n",
    "In Malloy, data is first described in a network, and the network on joined rectangles forms a reusable object called a `source`. Aggregate calculations are applied in a query operation, which can reference any 'locality' in the join network to compute results correctly.\n",
    "\n",
    "The above example in Malloy looks like:\n",
    "\n",
    "```\n",
    "query: table('duckdb:orders.csv') + {\n",
    " join_many: items is table('duckdb:order_items.csv')\n",
    " on order_id = items.order_id\n",
    "}\n",
    "-> {\n",
    " group_by: order_date\n",
    " aggregate:\n",
    " total_revenue is items.price.sum()\n",
    " total_shipping is shipping_cost.sum()\n",
    "order_by: 1\n",
    "}\n",
    "```\n",
    "\n",
    "which results in this output:\n",
    "\n",
    "| order_date| total_revenue | total_shipping |\n",
    "| --- | ---| --- |\n",
    "| 2022-01-01  | 6 | 5 |\n",
    "| 2022-01-02  | 5 | 3 |\n",
    "\n",
    "Here,\n",
    "\n",
    "```\n",
    "table('duckdb:orders.csv') + {\n",
    " join_many: items is table('duckdb:order_items.csv')\n",
    " on order_id = items.order_id\n",
    "}\n",
    "```\n",
    "\n",
    "is the __SOURCE__. The aggregate calculation,\n",
    "\n",
    "```\n",
    "total_revenue is items.price.sum()\n",
    "```\n",
    "is _local to item_,  and\n",
    "\n",
    "```\n",
    "total_shipping is shipping_cost.sum()\n",
    "```\n",
    "is _local to orders_.\n",
    "\n",
    "The above malloy query aggregates along a date dimension, but we can aggregate along any dimension dynamically, simply by updating the dimension as below:\n",
    "\n",
    "```\n",
    "query: table('duckdb:orders.csv') + {\n",
    " join_many: items is table('duckdb:order_items.csv')\n",
    " on order_id = items.order_id\n",
    "}\n",
    "-> {\n",
    " group_by: user_id\n",
    " aggregate:\n",
    " total_revenue is items.price.sum()\n",
    " total_shipping is shipping_cost.sum()\n",
    "order_by: 1\n",
    "}\n",
    "```\n",
    "\n",
    "| user_id | total_revenue | total_shipping |\n",
    "| ------- | ------------- | -------------- |\n",
    "| 1       | 4             | 3              |\n",
    "| 2       | 3             | 3              |\n",
    "| 3       | 4             | 2              |\n",
    "\n",
    "## Dimensional Freedom\n",
    "\n",
    "Malloy offers the power of 'Dimensional Freedom'. This concept allows you to produce results from anywhere in the join network, giving you the flexibility to view your data from different dimensions. The system also deduces a primary key, streamlines it, and formulates the calculation for you.\n",
    "\n",
    "### Source\n",
    "\n",
    "- In contrast to traditional SQL, Malloy's reusability lies in a source. \n",
    "\n",
    "```\n",
    "source: orders_items is table('duckdb:orders.csv') + {\n",
    " join_many: items is table('duckdb:order_items.csv')\n",
    " on order_id = items.order_id\n",
    " declare:\n",
    " total_revenue is items.price.sum()\n",
    " total_shipping is shipping_cost.sum()\n",
    "}\n",
    "```\n",
    "\n",
    "- A source can be named, like the above source is named `order_items`.\n",
    "- The sources describe the join relationships, like the above source describes the relationship between `orders` and `order_items`\n",
    "- Sources describe both aggregate and scalar calculations.\n",
    "- Source makes queries incredibly simple. For example, performing an aggregate calculation on the above source looks like this in malloy:\n",
    "\n",
    "```\n",
    "query: orders_items -> {\n",
    " group_by: order_date\n",
    " aggregate: total_revenue, total_shipping\n",
    " order_by: 1\n",
    "}\n",
    "```\n",
    "| order_date                | total_revenue | total_shipping |\n",
    "| ------------------------- | ------------- | -------------- |\n",
    "| 2022-01-01  | 6             | 5              |\n",
    "| 2022-01-02  | 5             | 3              |\n",
    "\n",
    " It recognizes that data naturally comes nested, and the need to separate them is an artifact of the SQL engine, not a real-world necessity.\n",
    " \n",
    "# Malloy's Features\n",
    " \n",
    "Malloy can query logs straight out of the box, providing a user-friendly interface for data management. It recognizes three types of join:\n",
    "\n",
    "1. Join_one: for a single item.\n",
    "2. Join_many: for multiple items.\n",
    "3. Join_cross: for cross joins.\n",
    "\n",
    "But that's not all. Malloy also writes nested data and handles non-rectangular data effectively, both in reading and writing. In fact, all Malloy queries read the data only once, which greatly increases efficiency.\n",
    "\n",
    "Furthermore, Malloy is compatible with a variety of systems, capable of writing queries against [BigQuery](https://cloud.google.com/bigquery/), [PostgreSQL](https://www.postgresql.org/), and [DuckDB](https://duckdb.org/).\n",
    "\n",
    "Malloy also offers a [VSCode plugin](https://marketplace.visualstudio.com/items?itemName=malloydata.malloy-vscode) which is a file of extension `.malloy` and notebook support which is a file of extension `.malloynb`. In addition, malloy offers in-built support for charting and visualization which you can learn more about [here](https://malloydata.github.io/documentation/visualizations/dashboards).\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Malloy presents a fresh approach to data management, breaking free from the rectangular confines of traditional SQL and data warehousing. By focusing on data's natural network structure, it enables efficient, real-time data operations that can revolutionize the way your business handles and utilizes data.\n",
    "\n",
    "I reckon this is something remarkable, and I expect to see it being adopted purely because it simplifies the data viewing aspect that will enable domain experts to focus on business logic than on what tables to join. I'll be keeping an eye on this project.\n",
    "\n",
    "Let me know your thoughts!\n",
    "\n",
    "You can find the link to the notebook [here](malloy.malloynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413227a5",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [Malloy Documentation](https://www.malloydata.dev/docs)\n",
    "- [Lloyd Tabb's talk](https://www.youtube.com/watch?v=zmmJgwc3oPI&embeds_referring_euri=https%3A%2F%2Fwww.datacouncil.ai%2F&source_ve_path=Mjg2NjY&feature=emb_logo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db536709",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <a href=\"https://www.buymeacoffee.com/alephthoughts\" target=\"_blank\">\n",
    "    <img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important; width: 217px !important;\">\n",
    "  </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
